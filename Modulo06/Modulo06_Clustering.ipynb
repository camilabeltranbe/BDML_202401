{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b7c0aa",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"../banner.jpg\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8239cd",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ignaciomsarmiento/BDML_202401/blob/main/Modulo06/Modulo06_Clustering.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5981868a",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "## Etapas\n",
    "\n",
    "Las etapas del análisis de clusters podemos resumirlas de la siguiente forma:\n",
    "\n",
    "1. Iniciamos con una matriz de datos\n",
    "\n",
    "    \\begin{align}\n",
    "X_{n\\times k}=\\left(\\begin{array}{cccc}\n",
    "x_{11} &  & \\dots & x_{1k}\\\\\n",
    "\\\\\n",
    "\\vdots &  & x_{ik} & \\vdots\\\\\n",
    "\\\\\n",
    "x_{n1} &  & \\dots & x_{nk} \n",
    "\\end{array}\\right)\n",
    "    \\end{align}\n",
    "\n",
    "2. Calculamos la matriz de distancia o disimilitud\n",
    "\n",
    "\\begin{align}\n",
    "D_{n\\times n}=\\left(\\begin{array}{ccccc}\n",
    "d_{11} &  & \\dots &  & d_{1n}\\\\\n",
    " & \\ddots\\\\\n",
    "\\vdots &  & d_{jj} &  & \\vdots\\\\\n",
    " &  &  & \\ddots\\\\\n",
    "d_{n1} &  & \\dots &  & d_{nn}\n",
    "\\end{array}\\right)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "3. Aplicamos el algoritmo de clustering. Existen varios tipos\n",
    "    - **basados en centroides**\n",
    "    - **basados en conectividad** \n",
    "    - **basados en densidades**\n",
    "    - **basados en distribuciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574001e2",
   "metadata": {},
   "source": [
    "## Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45a09f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"pacman\") #run this line if you use Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d98c842",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#packages\n",
    "require(\"pacman\")\n",
    "p_load(\"tidyverse\", #data wrangling\n",
    "       \"sf\",\n",
    "       \"ClustGeo\" # geographical clustering\n",
    "      ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d3c87f",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b26abf",
   "metadata": {},
   "source": [
    "En este ejemplo vamos a usar datos de 303 municipalidades franesa en el esutario del Girondaes un gran estuario navegable  localizado en el suroeste de Francia y que se forma por el encuentro entre dos ríos, el Dordoña y el Garona, justo aguas abajo del centro de Burdeos. \n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Charente-Maritime_department_relief_location_map.jpg/500px-Charente-Maritime_department_relief_location_map.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d4188",
   "metadata": {},
   "outputs": [],
   "source": [
    "db <- estuary$dat\n",
    "head(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.geo <- estuary$D.geo\n",
    "map <- estuary$map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c15c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e684353",
   "metadata": {},
   "outputs": [],
   "source": [
    "map<-st_as_sf(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d61ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel <- map  %>% filter(NOM_COMM%in% c(\"BORDEAUX\", \"ARCACHON\", \"ROYAN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b45068",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot() +\n",
    "  geom_sf(data = map, fill = NA) +\n",
    "  geom_sf_text(data = sel, aes(label = NOM_COMM)) +\n",
    "    theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a874d1",
   "metadata": {},
   "source": [
    "### Implementación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "k3 <- kmeans(db, centers = 3, nstart = 25)\n",
    "str(k3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44981784",
   "metadata": {},
   "source": [
    "La salida de `kmeans` posee mucha información útil siendo las  más importantes:\n",
    "\n",
    "   - clúster: Un vector de números enteros (de 1:k) que indica el clúster al que se asigna cada punto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa74005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(k3$cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff98da62",
   "metadata": {},
   "source": [
    "- centers: Una matriz de centros de los clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c328001",
   "metadata": {},
   "outputs": [],
   "source": [
    "k3$centers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac6a7cb",
   "metadata": {},
   "source": [
    "Generemos la prediccion en los datos y en el map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecd588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db<- db %>% mutate(cluster=factor(k3$cluster))\n",
    "map<- map %>% mutate(cluster=factor(k3$cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c618dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a88362",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023bbc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot() +\n",
    "  geom_sf(data = map, aes(fill = cluster)) +\n",
    "  geom_sf_text(data = sel, aes(label = NOM_COMM)) +\n",
    "    theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c72d609",
   "metadata": {},
   "source": [
    "Evaluemos el número de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab50902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_load(\"cluster\")\n",
    "# función para extraer el coeficiente de silhouette\n",
    "\n",
    "avg_sil <- function(k) {\n",
    "  km.res <- kmeans(db, centers = k, nstart = 25)\n",
    "  ss <- cluster::silhouette(km.res$cluster, dist(db))\n",
    "  mean(ss[, 3])\n",
    "}\n",
    "avg_sil(2)\n",
    "\n",
    "# Calcular el coeficiente de silhouette para  k = 2 hasta k = 6\n",
    "valores_sil <-  sapply(2:30,avg_sil)\n",
    "\n",
    "plot(2:30, valores_sil,\n",
    "       type = \"b\", pch = 19, frame = FALSE, \n",
    "       xlab=\"Número de clusters (K)\",\n",
    "       ylab = \"Coeficiente de Silhouette\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40a49df",
   "metadata": {},
   "outputs": [],
   "source": [
    "k30 <- kmeans(db, centers = 30, nstart = 25)\n",
    "map<- map %>% mutate(cluster=factor(k30$cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3563ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot() +\n",
    "  geom_sf(data = map, aes(fill = cluster)) +\n",
    "  geom_sf_text(data = sel, aes(label = NOM_COMM)) +\n",
    "    theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad3883e",
   "metadata": {},
   "source": [
    "\n",
    "## Caveat\n",
    "\n",
    "Los métodos de clustering son exploratorios: se pueden utilizar para evaluar la calidad de los datos y generar hipótesis. \n",
    "\n",
    "Pero no importa lo que entre en el algoritmo de agrupamiento, los clusters salen. Esta es una situación clásica de \"basura que entra, basura que sale\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07966b60",
   "metadata": {},
   "source": [
    "\n",
    "![](figs/Garbage-Model.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e2d9d0",
   "metadata": {},
   "source": [
    "\n",
    "Obviamente, esperamos que lo que se está metiendo en el análisis no sea basura, pero eso no garantiza que salga una \"pearl of wisdom\".\n",
    "\n",
    "La conclusión es que la agrupación es buena si es útil para responder el problema en particular. Pero, esto es difícil de evaluar.\n",
    "\n",
    "\n",
    "Hay medidas de cuán bueno es el agrupamiento. Funcionan según el principio de que las distancias entre los elementos del mismo grupo deben ser pequeñas y las distancias entre los elementos de diferentes grupos deben ser grandes. \n",
    "\n",
    "Esta es una verificación interna de la \"estrechez\" de los grupos, pero no garantiza que los grupos sean útiles y/o significativos para el problema bajo estudio. Esto requiere que el usuario utilice su capacidad y discernimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fed493",
   "metadata": {},
   "source": [
    "## Clustering Jerárquico\n",
    "\n",
    "- Este método es especialmente útil cuando no existen expectativas sobre los patrones y estructuras subyacentes de los datos. \n",
    "\n",
    "\n",
    "- Una característica atractiva es que no es necesario especificar el número de clusers a buscar a priori como en   k-medias \n",
    "\n",
    "\n",
    "- Este  mide la conectividad entre las observaciones en algún espacio de características o conjunto de datos. \n",
    "\n",
    "\n",
    "- Podemos usar los resultados para visualizar su similitud espacial entre sí en una variedad de niveles, típicamente en forma de dendrograma, que es una estructura similar a un árbol que muestra progresivamente las similitudes entre las observaciones.\n",
    "\n",
    "\n",
    "- En algunos casos puede informar a los otros métodos de clustering  basados en los patrones revelados. Por ejemplo, si el dendrograma revela dos grupos naturales, entonces una segunda etapa puede inicializar un algoritmo de k-medias con dos conglomerados. Al especificar el algoritmo de k-medias, podríamos comparar directamente la validez interna de ambos algoritmos  para determinar cuál es mejor para agrupar los datos a lo largo de una variedad de dimensiones (p. ej., conectividad, compacidad, etc.). \n",
    "\n",
    "\n",
    "- Hay dos tipos de agrupamiento jerárquico: \n",
    "    -  aglomerativo (de abajo hacia arriba) y \n",
    "    -  divisivo (de arriba hacia abajo).\n",
    "\n",
    "- Incorpora fácilmente la geografía"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe351c99",
   "metadata": {},
   "source": [
    "### Etapas\n",
    "\n",
    "1. Iniciamos con una matriz de datos\n",
    "\n",
    "    \\begin{align}\n",
    "X_{n\\times k}=\\left(\\begin{array}{cccc}\n",
    "x_{11} &  & \\dots & x_{1k}\\\\\n",
    "\\\\\n",
    "\\vdots &  & x_{ik} & \\vdots\\\\\n",
    "\\\\\n",
    "x_{n1} &  & \\dots & x_{nk} \n",
    "\\end{array}\\right)\n",
    "    \\end{align}\n",
    "\n",
    "2. Calculamos la matriz de distancia o disimilitud\n",
    "\n",
    "\\begin{align}\n",
    "D_{n\\times n}=\\left(\\begin{array}{ccccc}\n",
    "d_{11} &  & \\dots &  & d_{1n}\\\\\n",
    " & \\ddots\\\\\n",
    "\\vdots &  & d_{jj} &  & \\vdots\\\\\n",
    " &  &  & \\ddots\\\\\n",
    "d_{n1} &  & \\dots &  & d_{nn}\n",
    "\\end{array}\\right)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "3. Aplicamos el algoritmo de clustering jerárquico: depende como se define la conectividad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07d28b5",
   "metadata": {},
   "source": [
    "### Definición de la matriz de distancia o disimilitud:\n",
    "\n",
    "- Un problema de la distancia euclídiana, como medida de similaridad, es su dependencia de las diferentes escalas en que estén medidas las variables. \n",
    "\n",
    "- Escalas y rangos de variación diferentes pueden afectar al análisis de clusters.\n",
    "\n",
    "- Este problema se soluciona si en vez de calcular la distancia euclídea con puntuaciones directas se calcula con puntuaciones normalizadas. \n",
    "\n",
    "- Estandarizar las puntuaciones de los sujetos en las variables es uno de los procedimientos de normalización más frecuentes en análisis de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197b6882",
   "metadata": {},
   "source": [
    "EJEMPLO: Supongamos que estamos interesados en agrupar a una muestra de 5 familias en base al número de hijos, al\n",
    "sueldo en euros al mes y al tamaño de la casa en metros cuadrados. La matriz de datos de la que partimos es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4144622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a data frame in R\n",
    "Ej <- data.frame(Hijos = c(1, 1, 4, 0, 2),\n",
    "                Salario = c(723, 900, 800, 1205, 600),\n",
    "                Metros2 = c(60, 60, 80, 50, 65))\n",
    "\n",
    "# Print the data frame\n",
    "Ej\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d891b24",
   "metadata": {},
   "source": [
    "Podemos como antes calcular las distancias entre los sujetos a partir de las puntuaciones directas o bien podemos calcularlas a partir de las variables estandarizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a99d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix <- as.data.frame(as.matrix(dist(Ej, method = \"euclidean\")))\n",
    "distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86748cd7",
   "metadata": {},
   "source": [
    "Como puede observarse, las familias más parecidas son la familia primera y la tercera. Sin embargo, son familias que salvo en que tienen un salario similar son diferentes en el resto de las variables. Si por el contrario seleccionamos la opción estandarizar la matriz de distancias que obtenemos es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114c5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix2 <- as.data.frame(as.matrix(dist(scale(Ej), method = \"euclidean\")))\n",
    "distance_matrix2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb442d8d",
   "metadata": {},
   "source": [
    "- Con las puntuaciones estandarizadas las familias más parecidas son la primera y la segunda. \n",
    "\n",
    "- Es evidente que los resultados de un análisis de clusters son distintos si se parte de matrices de similaridad o distancia que ordenen a los sujetos de manera distinta. \n",
    "\n",
    "- Es por ello que en caso de variables medidas en escalas distintas es necesario normalizar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62126ee8",
   "metadata": {},
   "source": [
    "EJEMPLO 2.  Supongamos que tenemos los siguientes datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec1fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame in R\n",
    "D <- data.frame(Edad = c(22, 25, 30, 38, 42, 47, 55, 62, 61, 90),\n",
    "                Genero = factor(c(\"M\", \"M\", \"F\", \"F\", \"F\", \"M\", \"M\", \"M\", \"M\", \"M\")),\n",
    "                Estado_Civil = factor(c(\"Soltero\", \"Soltero\", \"Soltero\", \"Casado\", \"Casado\", \"Soltero\", \"Casado\", \"Divorciado\", \"Casado\", \"Divorciado\")),\n",
    "                Salario = c(18000, 23000, 27000, 32000, 34000, 20000, 40000, 42000, 25000, 70000),\n",
    "                tiene_hijos = factor(c(\"No\", \"No\", \"No\", \"Si\", \"Si\", \"No\", \"No\", \"No\", \"No\", \"Si\")),\n",
    "                Volumen_compras = factor(c(\"Bajo\", \"Bajo\", \"Bajo\", \"Alto\", \"Alto\", \"Bajo\", \"Medio\", \"Medio\", \"Medio\", \"Bajo\")))\n",
    "\n",
    "# Print the data frame\n",
    "D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c01eaf7",
   "metadata": {},
   "source": [
    "Distancia de Gower\n",
    "\n",
    "- Para una característica numérica, la diferencia parcial entre dos clientes i y j es la resta entre sus valores en la característica específica (en valor absoluto) dividida por el rango total de la característica. El rango de salario es 52000 (70000–18000) mientras que el rango de edad es 68 (90–22). \n",
    "    Note, hay que tener en cuenta si existen outliers o valores atípicos. Un valor erróneo extremadamente grande o pequeño afectaría directamente el rango y, por lo tanto, las diferencias en esa característica, distorsionando su importancia.\n",
    "\n",
    "-    Para una característica categórica, la diferencia parcial entre dos clientes es uno cuando ambos clientes tienen un valor diferente para esta característica. Cero en caso contrario.\n",
    "\n",
    "La Disimilitud de Gower entre ambos clientes es el promedio de disimilitudes parciales a lo largo de las diferentes características: \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d824d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_load(\"gower\")\n",
    "distance_matrix <- daisy(D, metric=\"gower\")\n",
    "distance_matrix_df <- as.data.frame(as.matrix(distance_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83754a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(22-25)/68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb78019",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(18000-23000)/52000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9aa6a9",
   "metadata": {},
   "source": [
    "Entre la primera y la segunda\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{(0,044118 + 0 + 0 + 0,096154 + 0 + 0)}{ 6} = 0,023379. \n",
    "\\end{align}\n",
    "\n",
    "Como el valor es cercano a cero, podemos decir que ambas observaciones son muy similares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c549cd3b",
   "metadata": {},
   "source": [
    "### Enlaces\n",
    "\n",
    "\n",
    "\n",
    "- Por lo tanto, con nuestros datos de distancia estandarizados, podemos entrenar un algoritmo de agrupamiento jerárquico, pero como el algoritmo procede en forma de pares, debemos especificar con precisión cómo se unen estos pares. \n",
    "\n",
    "\n",
    "- El método de enlace es el mecanismo para determinar cómo se unen los pares de datos.  Hay muchos métodos de vinculación entre los que elegir:\n",
    "\n",
    "   - *Enlace simple*\n",
    "   - *Enlace completo (complete linkage - CL)*\n",
    "   - *Enlace promedio de grupo (average )*\n",
    "   - *Enlace usando centroides (Centroid)*\n",
    "   - *Enlace de Ward*\n",
    "   \n",
    "   \n",
    "- Es importante señalar que, al igual que las medidas de distancia, no existe una guía en la literatura sobre cuál es el mejor método de enlace.\n",
    "\n",
    "\n",
    "- La selección del método de enlace generalmente depende de las preferencias específicas del problema o disciplina, por ejemplo, el enlace centroide es popular entre los genetistas y ward entre los economistas.\n",
    "\n",
    "\n",
    "- Se recomienda que se comparen varios métodos de enlace para descubrir patrones naturales de la manera más eficiente posible.\n",
    "\n",
    "\n",
    "- Es importante reiterar que solo los algoritmos jerárquicos requieren la especificación de un método de vinculación, sin embargo, todos los algoritmos de agrupamiento requieren la especificación y el cálculo de una distancia entre las observaciones, aunque alguno de ellos lo hacen de forma implícita.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc2822",
   "metadata": {},
   "source": [
    "#### Enlace completo (complete linkage - CL)\n",
    "   \n",
    "   El enlace completo o técnica del vecino más lejano, es lo opuesto al enlace simple y combina los clusters encontrando la distancia máxima entre las observaciones del cluster $G$ y las observaciones del cluster $H$:\n",
    "\n",
    "   \\begin{align}\n",
    "     d_{CL}(G, H)= max_{i\\in G,\\ i'\\in H} d_{ii'} \n",
    "   \\end{align}\n",
    "\n",
    "   En otras palabras, funciona combinando clusters en función de los puntos más alejados entre los dos clusters.\n",
    "   \n",
    "   ##### Ejemplo:\n",
    "\n",
    "|   | 1  | 2  | 3 | 4 | 5 |\n",
    "|---|----|----|---|---|---|\n",
    "| **1** | 0  |    |   |   |   |\n",
    "| **2** | 9  | 0  |   |   |   |\n",
    "| **3** | 3  | 7  | 0 |   |   |\n",
    "| **4** | 6  | 5  | 9 | 0 |   |\n",
    "| **5** | 11 | 10 | 2 | 8 | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b508b16d",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"figures/complete_link0.png\" />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009f0d62",
   "metadata": {},
   "source": [
    "|    | 35 | 1 | 2 | 4 |\n",
    "|----|----|---|---|---|\n",
    "| **35** | 0  |   |   |   |\n",
    "| **1** | 11 | 0 |   |   |\n",
    "| **2** | 10 | 9 | 0 |   |\n",
    "| **4** | 9  | 6 | 5 | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e9be86",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"figures/complete_link1.png\" />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4facd868",
   "metadata": {},
   "source": [
    "|    | 35 | 1 | 2 | 4 |\n",
    "|----|----|---|---|---|\n",
    "| **35** | 0  |   |   |   |\n",
    "| **1** | 11 | 0 |   |   |\n",
    "| **24** | 10 | 9 | 0 |   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4299e8cd",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"figures/complete_link.png\" />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b6dd7a",
   "metadata": {},
   "source": [
    "   - **Enlace simple**\n",
    "   \n",
    "   También conocido como técnica del vecino más cercano; en este método combinamos los clusters, basándonos en los dos puntos más cercanos de cada cluster. Para lograrlo, tomamos las distancias por pares entre las observaciones del cluster $G$ y las observaciones del cluster $H$, y guardamos la menor:\n",
    "\n",
    "$$d_{SL}(G, H)= min_{i\\in G,\\ i'\\in H} d_{ii'}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ff4b44",
   "metadata": {},
   "source": [
    "\n",
    "<div >\n",
    "<img src = \"figures/single_link.png\" />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d200b7",
   "metadata": {},
   "source": [
    "## Clustering Jerárquico en el Estuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6eae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db <- estuary$dat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989bd400",
   "metadata": {},
   "outputs": [],
   "source": [
    "D0 <- dist(db) # the socio-economic distances\n",
    "tree <- hclustgeo(D0) #clustering with ward distance\n",
    "\n",
    "# Plot\n",
    "plot(tree,hang = -1, label = FALSE, \n",
    "     xlab = \"\", sub = \"\",\n",
    "     main = \"Ward dendrogram with D0 only\")\n",
    "\n",
    "rect.hclust(tree ,k = 5, border = c(4,5,3,2,1))\n",
    "legend(\"topright\", legend = paste(\"cluster\",1:5), \n",
    "       fill=1:5,bty= \"n\", border = \"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "D0 <- dist(scale(db)) # the socio-economic distances\n",
    "\n",
    "tree <- hclustgeo(D0)\n",
    "plot(tree,hang = -1, label = FALSE, \n",
    "     xlab = \"\", sub = \"\",\n",
    "     main = \"Ward dendrogram with D0 only\")\n",
    "\n",
    "rect.hclust(tree ,k = 5, border = c(4,5,3,2,1))\n",
    "legend(\"topright\", legend = paste(\"cluster\",1:5), \n",
    "       fill=1:5,bty= \"n\", border = \"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67fc655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut the dendrogram to get the partition in 5 clusters\n",
    "P5 <- cutree(tree,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cbcdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "map<- map  %>% mutate(cluster=P5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot() +\n",
    "  geom_sf(data = map, aes(fill = as.factor(cluster))) +\n",
    "  geom_sf_text(data = sel, aes(label = NOM_COMM)) +\n",
    "    theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16c9e6",
   "metadata": {},
   "source": [
    "### Incorporemos las restricciones geograficas\n",
    "\n",
    "\n",
    "- Para obtener clusters más compactos espacialmente, incluimos en el proceso de clustering la matriz D1, que contiene las distancias entre los ayuntamientos de los municipios, junto con el parámetro de mezcla alpha que define la importancia relativa de D0 (distancias socioeconómicas) y D1 (distancias geográficas).\n",
    "\n",
    "\n",
    "    La matriz de distancias final utilizada para el clustering se calcula como una combinación ponderada de las dos matrices de distancias). La fórmula general para calcular la matriz de distancias combinada usando alpha es:\n",
    "$$\n",
    "    D=\\alpha ×D0+(1−\\alpha)×D.geo\n",
    "$$    \n",
    "\n",
    "En esta fórmula, D0 representa la matriz de distancias socioeconómicas y D.geola matriz de distancias geográficas. Al variar $\\alpha$, se ajusta la contribución relativa de cada tipo de distancia al resultado final del clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "D1 <- as.dist(D.geo) # the geographic distances between the municipalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663827b1",
   "metadata": {},
   "source": [
    "Ponderación de Distancias:\n",
    "\n",
    "\n",
    "### Selección del Parámetro  Alpha:\n",
    "- El parámetro de mezcla alpha, que varía entre [0,1], ajusta la importancia de D0 y D1 en el proceso de clustering.\n",
    "- Cuando alpha=0, las disimilitudes geográficas no se consideran, y cuando alpha=1, son las distancias socioeconómicas las que no se tienen en cuenta, formándose los clusters únicamente con las distancias geográficas.\n",
    "\n",
    "- La elección del valor de alpha debe ser considerada cuidadosamente en función de los objetivos específicos del problema. Puede ser útil realizar análisis exploratorios con varios valores de alpha para observar cómo cambian los clusters y seleccionar el valor que mejor capture las características importantes del trabajo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ae6531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "range.alpha <- seq(0,1,0.1)\n",
    "K <- 5\n",
    "cr <- choicealpha(D0, D1, range.alpha, \n",
    "  K, graph = FALSE)\n",
    "cr$Q # proportion of explained inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b644869a",
   "metadata": {},
   "source": [
    "El gráfico de las curvas Q0 y Q1 es una herramienta valiosa para seleccionar un valor de alpha que equilibre la pérdida de homogeneidad socioeconómica con la ganancia en cohesión geográfica.\n",
    "\n",
    "\n",
    "- **Q0**: Representa la homogeneidad socioeconómica de las particiones obtenidas. Refleja cuán similares son los municipios dentro de cada cluster en términos de sus características socioeconómicas.\n",
    "- **Q1**: Representa la homogeneidad geográfica. Indica cuán cerca están geográficamente los municipios dentro de cada cluster.\n",
    "\n",
    "\n",
    "### Implementando el Alpha Elegido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0506fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "treeD0D1 <- hclustgeo(D0,D1,alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ad29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(tree,hang = -1, label = FALSE, \n",
    "     xlab = \"\", sub = \"\",\n",
    "     main = \"Ward dendrogram with D0 and D1\")\n",
    "rect.hclust(tree ,k = 5, border = c(4,5,3,2,1))\n",
    "legend(\"topright\", legend = paste(\"cluster\",1:5), \n",
    "       fill=1:5,bty= \"n\", border = \"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680308ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "P5bis <- cutree(treeD0D1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6c8aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "map<- map  %>% mutate(cluster=P5bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot() +\n",
    "  geom_sf(data = map, aes(fill = as.factor(cluster))) +\n",
    "  geom_sf_text(data = sel, aes(label = NOM_COMM)) +\n",
    "    theme_bw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
